---
title: "Lab 3: Significance Tests and Reporting Results"
author: "Fabio Setti"
institute: "PSYC 7804 - Regression with Lab"
bibliography: Additional files/R packages.bib
csl: Additional files/apa.csl
notice: |
  @Wickham_RStudio_2023
title-slide-attributes:
  data-transition: "zoom"
  data-visibility: "uncounted"
format:
   revealjs:
      footer: "Lab 3: Significance Tests and Reporting Results"
      width: 1280
      height: 720
      chalkboard: true
      slide-number: c/t 
      theme: Fabio_theme/Fabio_theme.scss
      navigation-mode: linear
      controls: false
      auto-stretch: false
      header-includes:
        - <script src="Fabio_theme/Fabio_theme.js"></script>

editor: source
---


## Today's Packages and Data ü§ó

:::: {.columns}
::: {.column width="50%"}

```{r}
#| code-fold: true
#| eval: false
#| echo: true
#| code-line-numbers: false
#| code-summary: "Install Packages Code"
#| classes: code-150

install.packages("flextable")

# Tidyverse should be already installed
# install.packages("tidyverse")

```

```{r}
#| eval: true
#| echo: true
#| code-line-numbers: false
#| warning: false
#| classes: code-150

library(flextable)
library(tidyverse)
theme_set(theme_classic(base_size = 16, 
                        base_family = 'serif'))
```

</br>

<div style="font-size: 26px">

::: {.panel-tabset}
### `flextable`

The `flextable` package [@Gohel_etal_2024] helps create pretty tables from R. Can also be used to create publication ready APA style tables.
:::

</div>

:::
::: {.column width="50%"}


<center> **Data** </center>

</br>

```{r}
#| warning: false
#| classes: code-125
#| echo: true
#| code-line-numbers: false
#| output: true

insurance <- rio::import("https://github.com/quinix45/PSYC-7804-Regression-Lab-Slides/raw/refs/heads/main/Slides%20Files/Data/insurance.csv")

# let's peak at our variables
str(insurance)
```
:::
::::

## Predicting Insurance Charges

Let's find out whether body mass index (`bmi`) predicts health insurance charges (`charges`)


:::: {.columns}
::: {.column width="60%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

reg <- lm(charges ~ bmi, insurance)
summary(reg)
```
:::



::: {.column width="40%"}

::: {.fragment fragment-index=1}

The resulting predicted charge is:

<div style="font-size: 22px">

$\widehat{\mathrm{Charges}}_i = \$1192.94 + \$393.87 \times \mathrm{BMI}_i$

</div>

:::

::: {.fragment fragment-index=2}

Is the intercept meaningful in this case?

:::

</br>

::: {.fragment fragment-index=3}

In practice, before we interpret anything, we need to check the *p*-values associated with our output.  

:::

:::
::::

## *p*-values

Some guy named [R.A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) came up with the idea of *p*-values. The set up goes something like this:

:::: {.columns}
::: {.column width="80%"}

<ol style="font-size: 24px">

::: {.fragment fragment-index=1}
<li> I collected this sample and found that BMI predicts how much insurance will charge. But do these results tell me anything about the [population](https://en.wikipedia.org/wiki/Statistical_population){target="_blank"}? I can't really measure the entire population ü´§ </li>
:::

::: {.fragment fragment-index=2}
<li> üí° Let's resample from the population and repeat my experiment in *exactly the same way* an infinite number of times and see how often I get my result, a slope of 393.87, *or more*. Let me also assume that in reality there truly is no relation between BMI and insurance charge, and the slope is exactly 0 in reality ($H_0$, the null hypothesis) </li>
:::

::: {.fragment fragment-index=3}
<li> Under the assumptions that the true population slope is exactly 0, the ***p*-value** is the proportion of times that I find a slope of 393.87 or more if I were to repeat exactly the same experiment an infinite number of times. </li>
:::

</ol>



::: {.fragment fragment-index=4}
Fisher, being really good at math and knowing the [central limit theorem](https://gallery.shinyapps.io/CLT_mean/){target="_blank"}
, realized that we don't have to repeat experiments an infinite number of times (ok, thank you Fisher üòå).
:::

:::
::: {.column width="20%"}

<br>

<figure>
  <img src="Images/Fisher2.jpg">
  <figcaption style="font-size: 16px">R. A. Fisher (1890-1962), really good with the maths and stats, but also a pretty bad person</figcaption>
</figure>


:::
::::

## Sampling Distributions

<div style="font-size: 26px">  Given *most* statistics, we can figure out what a distribution of the results of an infinite number of experiments will look like. This is known as the **sampling distribution**, and is the target of significance testing. </div> 


:::: {.columns}
::: {.column width="30%"}

::: {.fragment fragment-index=1}
<div style="font-size: 22px; padding-top: 12px;"> 
If we assume the our slope really should be 0 (i.e., we assume $H_0$ is true), the sampling distribution should look something like the plot on the right:
</div>
:::

<ul style="font-size: 22px">

::: {.fragment fragment-index=2}
<li> Our value for the slope was $393.87$, which is way far off to the right. That means $393.87$ is extremely unlikely to come from a sampling distribution where $H_0$ is true. </li>
:::

::: {.fragment fragment-index=3}
<li> The ***p*-value**, which is $2.46*10^{-13}$, represents the probability of getting our slope (or a value more extreme), from the plot on the right (i.e., if $H_0$ is true). ***p*-values** say nothing about how likely/unlikely $H_1$ is. </li>
:::

</ul>


:::
::: {.column width="70%"}

::: {.fragment fragment-index=1}

```{r}
#| eval: true
#| echo: true 
#| code-fold: true
#| code-summary: "Plot code"
#| code-line-numbers: false

# you need to install this package 
library(extraDistr)

ggplot() +
  geom_function(fun = dlst, args = list(mu = 0, sigma = 53.25, df = 1336), color = "blue") +
  labs(x = "All the slopes if H0 is true") +
  xlim(-(53.25*3), (53.25*3)) +
  scale_y_continuous(expand = c(0,0)) +
    annotate("text", x = -2, y = .002, 
             label = "The spread of this distribution \n is determined by the stanrdard error of the slope, \n which is 53.25") +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y =  element_blank())
```
:::
:::
::::


## Where's the T üçµ?

<div style="font-size: 26px"> How did I get a *p*-value without any *t*-value? Although the plot on the previous slide looked like a normal distribution, it was actually a *t*-distribution with $\mu = 0$, $\sigma = 53.25$ and $df = 1336$. Just like any normal distribution, the units can be standardized such that $\sigma = 1$, resulting in the graph below to the right. </div>


:::: {.columns}
::: {.column width="30%"}


::: {.fragment fragment-index=2}
<div style="font-size: 24px; padding-top: 12px;">  This implies also rescaling our slope to get a value that can be place it on the new x-axis, thus we compute the **t-statistic**: </div>


$$t = \frac{b_1}{SE_{b_1}} = \frac{393.87}{53.25} = 7.397 $$


```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

pt(7.397, df = 1336, lower.tail = FALSE)*2
```

The *p*-value is the same as the regression output. 
:::

:::
::: {.column width="70%"}

::: {.fragment fragment-index=1}

```{r}
#| eval: true
#| echo: true 
#| code-fold: true
#| code-summary: "Plot code"
#| code-line-numbers: false

ggplot() +
  geom_function(fun = dt, args = list(df = 1336), color = "blue") +
  labs(x = "All the slopes if H0 is true, but standardized") +
    annotate("text", x = 0, y = .1, 
             label = "Hey, I am still the same distribution \n from the previous slide. People \n like me better when my X-axis \n looks like this!") +
  xlim(-3, 3) +
  scale_y_continuous(expand = c(0,0)) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y =  element_blank())
```
:::

:::
::::

## ...And the intercept

<div style="font-size: 26px"> Usually, we don't really care about the intercept, but here it illustrate where *t*-values fall when the corresponding *p*-value is high. </div> 

:::: {.columns}
::: {.column width="30%"}


::: {.fragment fragment-index=1}
<div style="font-size: 24px; padding-top: 18px; padding-bottom: 18px;"> Form the outptut, $t = \frac{b_0}{SE_{b_0}} = \frac{1192.94}{1664.80} = 0.717$. This time, the *t*-value is pretty close to the center of the plot </div>



```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

pt(.717, df = 1336, lower.tail = FALSE)*2

```
:::


<ul style="font-size: 22px">

::: {.fragment fragment-index=3}
<li> So, even by random chance, there is about a $47\%$ chance of getting a value of $1192.94$ *or more extreme*. </li>

**NOTE**: the total area under the curve is $1$, and the shaded area is $0.473$, the *p*-value. </li>
:::
</ul>

:::
::: {.column width="70%"}

::: {.fragment fragment-index=2}

```{r}
#| eval: true
#| echo: true 
#| code-fold: true
#| code-summary: "Plot code"
#| code-line-numbers: false


ggplot() +
  geom_function(fun = dt, args = list(df = 1336), color = "blue") +
  labs(x = "All the intercepts if H0 is true") +
  geom_vline(xintercept = 0.717, linetype = 2) +
  xlim(-3, 3) +
  annotate("text", x = .25, y = .1, label = "t-value of \n the intercept") +
  annotate("text", x = -2, y = .3, label = "we also look at the \n opposite side, two-tailed test") +
    geom_ribbon(data = data.frame(x = seq(0.717, 4, length.out = 100)), 
              aes(x = x, ymin = 0, ymax = dt(x, df = 1336)), 
              fill = "lightblue", alpha = 0.5) +
  geom_ribbon(data = data.frame(x = seq(-0.717, -4, length.out = 100)), 
              aes(x = x, ymin = 0, ymax = dt(x, df = 1336)), 
              fill = "lightblue", alpha = 0.5) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(limits = c(-3, 3), breaks = c(-2, 0, 0.717, 2)) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y =  element_blank())
```
:::

:::
::::

## Type I Error Rate and Significance 

*p*-values have meaning even without any significance test. *Significance tests* happen only once we choose to make binary decisions based on *p*-values. At some point some folks decided that $p < .05 =$ *significant*. But,

::: {.fragment fragment-index=1}

> surely, God loves the .06 nearly as much as the .05 [@Rosnow_Rosenthal_1989, p. 1277]

:::

::: {.fragment fragment-index=2}

Type I error rate ($\alpha$) is thus not a bug of significance testing; it's a feature. Turning *p*-values into binary decisions (accept/reject $H_0$) implies that there is always a non-zero chance (the *p*-value being that chance) that our results come from $H_0$ (i.e., we are wrong). 

:::


::: {.fragment fragment-index=3}

So, significance testing is like gambling üé∞, where we think a 1 in 20 or less chances of being wrong is good odds. Sometimes we end up on the wrong side of chance, and we make the wrong conclusion. 
:::

::: {.fragment fragment-index=4}
And slightly unsettling is the fact that you cannot know which of your decisions based on *p*-values is the "wrong" one üòß.  
:::

## Confidence Intervals

We can also easily extract $95\%$ confidence intervals (CIs) for our intercept and slope:

:::: {.columns}
::: {.column width="60%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-150

confint(reg)
```

:::
::: {.column width="40%"}

::: {.fragment fragment-index=1}
Confidence intervals carry the same information as *p*-values. The respective *p*-value will be significant if the confidence interval does not include 0. 
:::

:::
::::


Now, as mention in the main lecture:


<ul style="font-size: 28px">

::: {.fragment fragment-index=2}
<li> **Incorrect interpretation**: "There is a 95% chance that the true value is within the confidence interval." </li>
:::

::: {.fragment fragment-index=3}
<li> **Correct interpretation**: "If I were to repeat the experiment an infinite number of times, 95% of my observed values would be within the confidence interval." </li>
:::

</ul>

::: {.fragment fragment-index=4}
I will not elaborate further, but see [here](https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval){target="_blank"} for more.
:::

## APA Style Report

...ok, I am done rambling, here's how you report the results in APA style:

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

summary(reg)
```


:::

::: {.column width="50%"}

<div style="font-size: 36px"> 
::: {.callout-note}

## APA style report

Simple linear regression analysis indicated that BMI significantly positively predicted insurance charges, *b* = 393.87, *t*(1336) = 7.4, *p* < .001, 95\%CI [289.41; 498.34]. The predictor explained a significant proportion of variance in insurance charges,  *R*<sup>2</sup> = .04, *F*(1, 1336) = 54.71, *p* < .001. 
::: 
</div>

::: {.fragment fragment-index=1}
Although not discussed in this lab, we will return to $R^2$ soon. 
:::

:::
::::


## ANOVA Output

If for some reason you prefer the ANOVA-type outputs, you can also get that for any type of `lm()` regression

:::: {.columns}
::: {.column width="40%"}

<br>

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

anova(reg)
```

:::

::: {.column width="60%"}

<br>

::: {.fragment fragment-index=1}

Later in the course, we will learn all about how ANOVA is a regression is disguise ü•∏. 

:::

<br>

::: {.fragment fragment-index=2}

For now, notice that this ANOVA output provides the same *F*-statistic and *p*-value that were in the output for the $R^2$ on the previous slide. 

:::

:::
::::


## Creating APA Style regression tables

To not have to manually recreate result tables over and over, I created a function that generates APA style regression tables ‚ú®. The  function code is [here](https://github.com/quinix45/PSYC-7804-Regression-Lab-Slides/blob/main/Slides%20Files/R_scripts/Regression_flextable.R){target="_blank"} if you are curious. 


:::: {.columns}
::: {.column width="60%"}

```{r}
#| eval: false
#| echo: true 
#| code-line-numbers: false
#| classes: code-125


# load the function (`source()` runs R code from other files)
source("https://github.com/quinix45/PSYC-7804-Regression-Lab-Slides/raw/refs/heads/main/Slides%20Files/R_scripts/Regression_flextable.R")

# any regression model
reg_model <- lm(charges ~ bmi + sex, insurance)

# create the table
table <- regression_flextable(reg_model)

# save the table to as a word doc. You should see the files in the `path` argument appear in your working directory
save_as_docx(table, path = "reg_table.docx")

```

::: {.fragment fragment-index=1}
<ul>
<li> The `save_as_...` functions that save the table to a file come from the `flextable` package (really good package üòç). My function also uses functions from `flextable` to format the regression table. </li>
</ul>
:::

:::


::: {.column width="40%"}

::: {.fragment fragment-index=2}

**`regression_flextable()` Arguments**

<ol style="font-size: 24px">
<li> `lm_object`: An `lm()` regression model , title = "", var_names = NULL, intercept = TRUE </li>

<li> `title = ""`: The table title (must be a character). </li>

<li> `var_names = NULL`: Names for first column of the table (the variables). Must be a character vector of the same length of the table rows. </li>


<li> `intercept = TRUE`: Set to `FALSE` if the intercept is not wanted (e.g., for standardized regression). </li>

</ol>
:::

:::
::::


## Table Output

If you open the `reg_table.docx` document that was just saved to your working directory, you should hopefully see a table like the one below

:::: {.columns}
::: {.column width="35%"}

<div style="font-size: 24px"> Usually, you don't want the R variable names as row names. You can change them with the `var_names = ` argument: </div>

<br>
<br>
<br>

```{r}
#| eval: false
#| echo: true 
#| classes: code-125
#| code-line-numbers: false

table <- regression_flextable(reg_model,
         var_names = c("Intercept", 
                       "BMI", 
                       "Sex"))

save_as_docx(table, 
       path = "reg_table_names.docx")

```


:::
::: {.column width="65%"}

```{r}
# load the function (`source()` runs R code from other files)
source("https://github.com/quinix45/PSYC-7804-Regression-Lab-Slides/raw/refs/heads/main/Slides%20Files/R_scripts/Regression_flextable.R")

# any regression model
reg_model <- lm(charges ~ bmi + sex, insurance)

# print
regression_flextable(reg_model)
```

<ul style="font-size: 24px">
<li> Updated row names: </li>
</ul>

```{r}
regression_flextable(reg_model, 
                     var_names = c("Intercept", "BMI", "Sex"))
```


:::
::::





## References 

<div id="refs"> </div>




