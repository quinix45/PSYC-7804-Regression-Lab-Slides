---
title: "Lab 5: Added Variable Plots and Bootstrapping"
author: "Fabio Setti"
institute: "PSYC 7804 - Regression with Lab"
bibliography: Additional files/R packages.bib
csl: Additional files/apa.csl
notice: |
  @Fox_etal_2024
title-slide-attributes:
  data-transition: "zoom"
  data-visibility: "uncounted"
format:
   revealjs:
      footer: "Lab 5: Added Variable Plots and Bootstrapping"
      width: 1280
      height: 720
      chalkboard: true
      slide-number: c/t 
      theme: Fabio_theme/Fabio_theme.scss
      navigation-mode: linear
      controls: false
      auto-stretch: false
      header-includes:
        - <script src="Fabio_theme/Fabio_theme.js"></script>

editor: source
---

## Data for Today

:::: {.columns}
::: {.column width="60%"}

Let's continue with the example from  [Lab 4](https://raw.githack.com/quinix45/PSYC-7804-Regression-Lab-Slides/main/Slides%20Files/Lab%204.html){target="_blank"}


```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125


WH_2024 <- rio::import("https://github.com/quinix45/PSYC-7804-Regression-Lab-Slides/raw/refs/heads/main/Slides%20Files/Data/World_happiness_2024.csv")

# let's peak at our variables
str(WH_2024, vec.len = 2)
```

:::
::: {.column width="40%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

# not needed, but makes things cleaner

reg_vars <- WH_2024[, c("Happiness_score",
                        "Log_GDP",
                        "Freedom")]
```


```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125


library(tidyverse)
theme_set(theme_classic(base_size = 14, 
                        base_family = 'serif'))
```

:::
::::

## Partial regression coefficients

In lab 4, we used `Log_GDP` and `Freedom` to predict `Happiness_score`. We observed that the results were very different when we use both variables together compared to when we look at them separately

:::: {.columns}
::: {.column width="50%"}

The intercept and slopes with both predictors in the model

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

reg_full <- lm(Happiness_score ~ Log_GDP + Freedom, 
          reg_vars)

coef(reg_full)
```


:::
::: {.column width="50%"}

The intercept and slopes with separate models with one predictor are quite different

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

reg_free <- lm(Happiness_score ~ Freedom, 
              reg_vars)
coef(reg_free)


reg_GDP <- lm(Happiness_score ~ Log_GDP, 
              reg_vars)
coef(reg_GDP)
```

:::
::::

<br>

The catch is that the model that includes both predictors calculates **partial regression coefficients**.

## "Manually" Calculate partial regression coefficients

Personally, the concept of **partial regression coefficients** starts making sense once I "computed" them myself and see what is going on behind the scenes. 

:::: {.columns}
::: {.column width="50%"}

Partial regression coefficient for `Log_GDP`

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

resid_happy_Free <- residuals(lm(Happiness_score ~ Freedom, 
               reg_vars))

resid_GDP <- residuals(lm(Log_GDP ~ Freedom, 
              reg_vars))

# the 0 + takes out the intercept, which is exactly 0 anyway in this case 
coef(lm(resid_happy_Free ~ 0 + resid_GDP))
```


:::
::: {.column width="50%"}

Partial regression coefficient for `Freedom`

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

resid_happy_GDP <- residuals(lm(Happiness_score ~ Log_GDP, 
               reg_vars))

resid_Free <- residuals(lm(Freedom ~ Log_GDP, 
              reg_vars))

# the 0 + takes out the intercept, which is exactly 0 anyway in this case 
coef(lm(resid_happy_GDP ~ 0 + resid_Free))
```
:::
::::

So, when you run multiple regression, all your slopes are calculated based on the residuals *after accounting for all the other variables in the model*.


## Added variable plots 

Then, added variables plots are simply plots between the residuals of one the predictor and $Y$ that result by taking out the variance explained by all the other variables. 

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

ggplot() +
  geom_point(aes(y = resid_happy_Free, 
                 x = resid_GDP))

```

:::
::: {.column width="50%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

ggplot() +
  geom_point(aes(y = resid_happy_GDP, 
                 x = resid_Free))

```
:::
::::

The slopes that you get when you include both predictors are the slopes for the lines of best fit these 2 plots.

## The Quick way: `avPlots()` function from `car`  

:::: {.columns}
::: {.column width="75%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125


car::avPlots(reg_full)
```
:::
::: {.column width="25%"}

To get added variable plots in practice you would use the `avPlot()` function. 

When you have more than 2 predictors, it is not possible to build a visualization of all variables at once like a 3D plot. Added variable plots can help you visualize regression results no matter the number of predictors!
:::
::::


## Bootstrapping

Bootstrapping [@efronBootstrapMethodsAnother1977] is a really smart idea to avoid doing math! You probably have seen some complicated equations that need to be derived to calculate confidence intervals for statistics (e.g., see [here](https://agleontyev.netlify.app/post/2019-09-05-calculating-r-squared-confidence-intervals/){target="_blank"}
fro the 95\% CI of $R^2$).

Turns out that even more complex math goes behind figuring out the complicated equations ðŸ˜± Usually, that involves figuring out what is the theoretical sampling distribution of a certain statistic for an infinite number of experiments.  

Instead bootstrapping says:


![](Images/bootstrap_diagram.png)





## "By Hand" Example of Bootstrapping

As always, we can do things ourselves to get a better understanding of the process.

:::: {.columns}
::: {.column width="40%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125
#| code-fold: true
#| code-summary: "Bootstrap $R^2$ code"

r_squared <- c()

set.seed(34677)

for(i in 1:2000){

# sample from data 
sample <- sample(1:nrow(reg_vars), 
                 replace = TRUE)  

dat_boot <- reg_vars[sample,]

# Run regression
reg_boot <- lm(Happiness_score ~ Log_GDP + Freedom, 
               dat_boot)  

# Save R^2
r_squared[i] <- summary(reg_boot)$r.squared
}
```


<div style="font-size: 24px">  
There is a lot of value in understanding how the code above works, but the main point is that we are running the same regression 2000 times with a different sample from our data, and then saving the $R^2$ that we get every time. 
</div>

The $R^2$ from our regression with both variables was

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

summary(reg_full)$r.squared
```


:::
::: {.column width="60%"}

If we look out the distribution of the all the 2000 $R^2$ we get 

```{r}
#| eval: true
#| echo: true 
#| out-width: "80%"
#| code-line-numbers: false

# need to run bootstrap code on the left first
hist(r_squared)
```

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false

quantile(r_squared, c(.025, .5, .975))

```


:::
::::

## The Quick way: `Boot()` function from `car`  

Once again, the `car` package comes to the rescue

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

set.seed(875)
boot_model <- car::Boot(reg_full, R = 2000)

confint(boot_model, type = "perc")
```

The confidence interval for $R^2$ is a bit annoying to get from `car`, so here we just have the CIs for intercept and slopes

:::
::: {.column width="50%"}

These are our normal confidence intervals from the regression:

```{r}
#| eval: true
#| echo: true 
#| code-line-numbers: false
#| classes: code-125

confint(reg_full)
```
:::
::::

Bootstrapping becomes more and more accurate as sample size increases. Here it may not be as accurate because we only have 140 observations, although it seems to do alright.


## References 

<div id="refs"> </div>










